From 9e27e396429f6e7a22d07a51d885eaba3f17df44 Mon Sep 17 00:00:00 2001
From: hydai <z54981220@gmail.com>
Date: Tue, 15 Jul 2025 09:12:18 +0000
Subject: [PATCH] feat(rocm): workaround for ROCm platform

---
 CMakeLists.txt             |  4 +++-
 cmake/FindFilesystem.cmake |  2 +-
 cmake/WASINNDeps.cmake     | 16 ++++++++++++++--
 lib/loader/CMakeLists.txt  |  6 ++++--
 rocm.sh                    | 38 ++++++++++++++++++++++++++++++++++++++
 5 files changed, 60 insertions(+), 6 deletions(-)
 create mode 100755 rocm.sh

diff --git a/CMakeLists.txt b/CMakeLists.txt
index 0ece9523..698cf83e 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -1,12 +1,13 @@
 # SPDX-License-Identifier: Apache-2.0
 # SPDX-FileCopyrightText: 2019-2024 Second State INC
 
-cmake_minimum_required(VERSION 3.15)
+cmake_minimum_required(VERSION 3.18)
 cmake_policy(SET CMP0091 NEW)
 if (CMAKE_VERSION VERSION_GREATER_EQUAL "3.24.0")
   cmake_policy(SET CMP0135 NEW)
 endif()
 project(WasmEdge LANGUAGES CXX C)
+set (CMAKE_CXX_STANDARD 17)
 
 # CMake build type.
 if(NOT CMAKE_BUILD_TYPE)
@@ -92,6 +93,7 @@ option(WASMEDGE_PLUGIN_WASI_NN_GGML_LLAMA_NATIVE "Enable LLAMA_NATIVE(AVX/AVX2/F
 option(WASMEDGE_PLUGIN_WASI_NN_GGML_LLAMA_BLAS "Enable LLAMA_BLAS in the WASI-NN GGML backend." OFF)
 option(WASMEDGE_PLUGIN_WASI_NN_GGML_LLAMA_CUBLAS "Enable LLAMA_CUBLAS in the WASI-NN GGML backend." OFF)
 option(WASMEDGE_PLUGIN_WASI_NN_GGML_LLAMA_METAL "Enable LLAMA_METAL in the WASI-NN GGML backend. Available on MacOS arm64 only." ON)
+option(WASMEDGE_PLUGIN_WASI_NN_GGML_LLAMA_HIP "Enable GGML_HIP in the WASI-NN GGML backend." OFF)
 option(WASMEDGE_PLUGIN_WASI_NN_WHISPER_METAL "Enable GGML_METAL in the WASI-NN WHISPER backend. Available on MacOS arm64 only." ON)
 option(WASMEDGE_PLUGIN_WASI_NN_WHISPER_CUDA "Enable GGML_CUDA in the WASI-NN WHISPER backend." OFF)
 #   WASI plug-in: WASI-Poll proposal.
diff --git a/cmake/FindFilesystem.cmake b/cmake/FindFilesystem.cmake
index 09a6630d..d8872a17 100644
--- a/cmake/FindFilesystem.cmake
+++ b/cmake/FindFilesystem.cmake
@@ -222,5 +222,5 @@ cmake_pop_check_state()
 set(Filesystem_FOUND ${_found} CACHE BOOL "TRUE if we can compile and link a program using std::filesystem" FORCE)
 
 if(Filesystem_FIND_REQUIRED AND NOT Filesystem_FOUND)
-    message(FATAL_ERROR "Cannot Compile simple program using std::filesystem")
+	#message(FATAL_ERROR "Cannot Compile simple program using std::filesystem")
 endif()
diff --git a/cmake/WASINNDeps.cmake b/cmake/WASINNDeps.cmake
index cd687296..f53373e2 100644
--- a/cmake/WASINNDeps.cmake
+++ b/cmake/WASINNDeps.cmake
@@ -315,6 +315,15 @@ function(wasmedge_setup_llama_target target)
       set(GGML_CUDA OFF)
     endif()
 
+    if(WASMEDGE_PLUGIN_WASI_NN_GGML_LLAMA_HIP)
+	    message(STATUS "WASI-NN GGML LLAMA backend: Enable GGML_HIP")
+	    set(GGML_HIP ON)
+	    add_compile_definitions(GGML_USE_HIP)
+    else()
+	    message(STATUS "WASI-NN GGML LLAMA backend: Disable GGML_HIP")
+	    set(GGML_HIP OFF)
+    endif()
+
     if(APPLE AND CMAKE_SYSTEM_PROCESSOR STREQUAL "arm64" AND WASMEDGE_PLUGIN_WASI_NN_GGML_LLAMA_METAL)
       message(STATUS "WASI-NN GGML LLAMA backend: Enable GGML_METAL")
       set(GGML_METAL ON)
@@ -329,8 +338,8 @@ function(wasmedge_setup_llama_target target)
     include(FetchContent)
     FetchContent_Declare(
       llama
-      GIT_REPOSITORY https://github.com/ggml-org/llama.cpp.git
-      GIT_TAG        b5896
+      GIT_REPOSITORY https://github.com/hydai/llama.cpp.git
+      GIT_TAG        rocm
       GIT_SHALLOW    FALSE
     )
     FetchContent_MakeAvailable(llama)
@@ -344,6 +353,9 @@ function(wasmedge_setup_llama_target target)
     if(WASMEDGE_PLUGIN_WASI_NN_GGML_LLAMA_CUBLAS)
       set_property(TARGET ggml-cuda PROPERTY POSITION_INDEPENDENT_CODE ON)
     endif()
+    if(WASMEDGE_PLUGIN_WASI_NN_GGML_LLAMA_HIP)
+      set_property(TARGET ggml-hip PROPERTY POSITION_INDEPENDENT_CODE ON)
+    endif()
     # Ignore unused function warnings at common.h in llama.cpp.
     if(CMAKE_CXX_COMPILER_ID MATCHES "GNU|Clang")
       target_compile_options(${target}
diff --git a/lib/loader/CMakeLists.txt b/lib/loader/CMakeLists.txt
index 2b65a2c2..4b70393c 100644
--- a/lib/loader/CMakeLists.txt
+++ b/lib/loader/CMakeLists.txt
@@ -11,7 +11,8 @@ target_link_libraries(wasmedgeLoaderFileMgr
   PUBLIC
   wasmedgeCommon
   wasmedgeSystem
-  std::filesystem
+  stdc++fs
+  #std::filesystem
 )
 
 if(NOT WIN32)
@@ -51,5 +52,6 @@ target_link_libraries(wasmedgeLoader
   PUBLIC
   wasmedgeCommon
   wasmedgeLoaderFileMgr
-  std::filesystem
+  #std::filesystem
+  stdc++fs
 )
diff --git a/rocm.sh b/rocm.sh
new file mode 100755
index 00000000..d2401249
--- /dev/null
+++ b/rocm.sh
@@ -0,0 +1,38 @@
+export build_number=b5896
+export wasmedge_version=0.14.1
+export build_dir=build_${wasmedge_version}_${build_number}
+export output_name=WasmEdge-plugin-wasi_nn-ggml-${build_number}-rocm-${wasmedge_version}-ubuntu24.04_x86_64.tar.gz
+export output_dir=${build_dir}/plugins/wasi_nn
+export build_options="-DWASMEDGE_PLUGIN_WASI_NN_BACKEND=GGML -DWASMEDGE_PLUGIN_WASI_NN_GGML_LLAMA_BLAS=OFF"
+export tar_name=wasi_nn-ggml
+export output_bin=libwasmedgePluginWasiNN.so
+export CXXFLAGS="-Wno-error"
+
+git config --global --add safe.directory $(pwd)
+rm -rf ${build_dir}
+export HIPCXX="$(hipconfig -l)/clang"
+export HIP_PATH="$(hipconfig -R)"
+export CC="$(hipconfig -l)/clang"
+export CXX="$(hipconfig -l)/clang"
+export ROCM_PATH="/opt/rocm-6.4.0"
+export AMDGPU_TARGETS="gfx942"
+
+HIPCXX="$(hipconfig -l)/clang" HIP_PATH="$(hipconfig -R)" cmake -B${build_dir} -GNinja \
+        -DCMAKE_BUILD_TYPE=Release \
+	-DLDFLAGS="-L$ROCM_PATH/lib -Wl,-rpath=$ROCM_PATH/lib -L$ROCM_PATH/lib64 -Wl,-rpath=$ROCM_PATH/lib64 -lhipblas -lamdhip64 -lrocblas" \
+	-DCPPFLAGS="-DGGML_USE_HIP -DGGML_USE_CUDA" \
+	-D_GLIBCXX_USE_CXX11_ABI=1 \
+        -DWASMEDGE_PLUGIN_WASI_NN_GGML_LLAMA_NATIVE=OFF \
+        -DWASMEDGE_BUILD_AOT_RUNTIME=OFF \
+        -DWASMEDGE_USE_LLVM=OFF \
+        -DWASMEDGE_BUILD_TOOLS=OFF \
+        ${build_options} \
+	-DWASMEDGE_PLUGIN_WASI_NN_GGML_LLAMA_HIP=ON
+
+cmake --build ${build_dir}
+
+echo "Copying ${tar_name} backend:"
+cp -f ${output_dir}/${output_bin} ${output_bin}
+tar -zcvf plugin_${tar_name}.tar.gz ${output_bin}
+
+mv plugin_wasi_nn-ggml.tar.gz ${output_name}
-- 
2.43.0

